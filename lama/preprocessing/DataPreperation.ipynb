{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAMA into the Wild Part1: DataPreperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this section We will preprocess the Data that we needed in the whole program. The result will be stored in `../data/pre`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import typing as t\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import DATA_DIR\n",
    "from lama.util import to_tuple, identity\n",
    "from lama.util.decorators import enable_logging\n",
    "from lama.util.StreamerBuilder import StreamerBuilder\n",
    "from lama.preprocessing.DataProcessor import nans, change_object_col, reformat_dataframe, split_with_index, standarize_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Define Global Constants\n",
    "\n",
    "To make our reading and writing more easier, we decide to define some global constants below, you can change them if you'd like to write to another location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = os.path.join(DATA_DIR, \"pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process looks alike, we will handle them one by one.\n",
    "\n",
    "- filter out Nan values\n",
    "- check unique columns\n",
    "- convert object values to numericals\n",
    "- catagorize discrete and continous features\n",
    "- scaling columns with Standardizer or Normalizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test\n",
    "\n",
    "We will first handle train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'), header=0)\n",
    "df_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'), header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test nans: \n",
      "first_active_month    1\n",
      "card_id               0\n",
      "feature_1             0\n",
      "feature_2             0\n",
      "feature_3             0\n",
      "dtype: int64\n",
      "\n",
      "df_train nans: \n",
      "first_active_month    0\n",
      "card_id               0\n",
      "feature_1             0\n",
      "feature_2             0\n",
      "feature_3             0\n",
      "target                0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check nans\n",
    "print(f'df_test nans: \\n{nans(df_test)}\\n')\n",
    "print(f'df_train nans: \\n{nans(df_train)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in `df_test` there is one nan row, although it is trival compared to the total value, we choose to drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = df_test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on to next section. lets check if there is abnormal distribution in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unexpected value: 2207\n",
      "<Figure size 432x288 with 1 Axes>\n"
     ]
    }
   ],
   "source": [
    "sns.histplot(df_train['target'], kde=True).set(title=\"HistPlot of Train Target\")\n",
    "unexpected = (df_train['target'] < -30).sum()\n",
    "print(f'unexpected value: {unexpected}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there exists some unexpected values when target < -30.\n",
    "\n",
    "\n",
    "One more thing to notice is the distributiton is symmetric to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'HistPlot of Train Target')]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Figure size 432x288 with 1 Axes>\n"
     ]
    }
   ],
   "source": [
    "df_train_copy = df_train[df_train['target'] > -30]\n",
    "sns.histplot(df_train_copy['target'], kde=True).set(title=\"HistPlot of Train Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we check if the id is unique, this procedure is important as we might need to outer join other datasets with id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_count = df_train_copy.shape[0]\n",
    "test_count = df_test_copy.shape[0]\n",
    "print(df_train_copy['card_id'].nunique() == train_count)\n",
    "print(df_test_copy['card_id'].nunique() == test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 199710 entries, 0 to 201916\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   first_active_month  199710 non-null  object \n",
      " 1   card_id             199710 non-null  object \n",
      " 2   feature_1           199710 non-null  int64  \n",
      " 3   feature_2           199710 non-null  int64  \n",
      " 4   feature_3           199710 non-null  int64  \n",
      " 5   target              199710 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert obejct to numeric values, as we seen above, there are two object values, since the card_id is a foreign key bound to match more features in other dataset, we'll leave it intact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['first_active_month']\n",
    "df_temps = reformat_dataframe(df_test_copy.append(df_train_copy), features, change_object_col)\n",
    "df_test_copy, df_train_copy = to_tuple(split_with_index(df_temps, test_count))\n",
    "del df_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "After change the columns we would like to see if the train and test features are evenly splitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Figure size 432x288 with 1 Axes>\n",
      "<Figure size 432x288 with 1 Axes>\n",
      "<Figure size 432x288 with 1 Axes>\n",
      "<Figure size 432x288 with 1 Axes>\n"
     ]
    }
   ],
   "source": [
    "features = ['first_active_month', 'feature_1', 'feature_2', 'feature_3']\n",
    "for feature in features:\n",
    "    (df_train_copy[feature].value_counts().sort_index() / train_count).plot()\n",
    "    (df_test_copy[feature].value_counts().sort_index() / test_count).plot()\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('ratio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to standarize the features, since not every model need standarized data, we will just leave the builder here uncollected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StreamerBuilder.build([df_test_copy, df_train_copy]) \\\n",
    "    .map(lambda df: reformat_dataframe(df, features, standarize_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to write the result back, and fetch when we needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy.to_csv(os.path.join(OUT_DIR, 'test_pre.csv'), index=False)\n",
    "df_train_copy.to_csv(os.path.join(OUT_DIR, 'train_pre.csv'), index=False)\n",
    "\n",
    "del df_test, df_test_copy, df_train, df_train_copy, features, test_count, train_count, unexpected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merchant Data purge\n",
    "\n",
    "Now we will hava a look at merchants.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334696 entries, 0 to 334695\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   merchant_id                  334696 non-null  object \n",
      " 1   merchant_group_id            334696 non-null  int64  \n",
      " 2   merchant_category_id         334696 non-null  int64  \n",
      " 3   subsector_id                 334696 non-null  int64  \n",
      " 4   numerical_1                  334696 non-null  float64\n",
      " 5   numerical_2                  334696 non-null  float64\n",
      " 6   category_1                   334696 non-null  object \n",
      " 7   most_recent_sales_range      334696 non-null  object \n",
      " 8   most_recent_purchases_range  334696 non-null  object \n",
      " 9   avg_sales_lag3               334683 non-null  float64\n",
      " 10  avg_purchases_lag3           334696 non-null  float64\n",
      " 11  active_months_lag3           334696 non-null  int64  \n",
      " 12  avg_sales_lag6               334683 non-null  float64\n",
      " 13  avg_purchases_lag6           334696 non-null  float64\n",
      " 14  active_months_lag6           334696 non-null  int64  \n",
      " 15  avg_sales_lag12              334683 non-null  float64\n",
      " 16  avg_purchases_lag12          334696 non-null  float64\n",
      " 17  active_months_lag12          334696 non-null  int64  \n",
      " 18  category_4                   334696 non-null  object \n",
      " 19  city_id                      334696 non-null  int64  \n",
      " 20  state_id                     334696 non-null  int64  \n",
      " 21  category_2                   322809 non-null  float64\n",
      "dtypes: float64(9), int64(8), object(5)\n",
      "memory usage: 56.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_merchant = pd.read_csv(os.path.join(DATA_DIR, 'merchants.csv'), header=0)\n",
    "df_merchant.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334696 334633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "merchant_id                        0\n",
       "merchant_group_id                  0\n",
       "merchant_category_id               0\n",
       "subsector_id                       0\n",
       "numerical_1                        0\n",
       "numerical_2                        0\n",
       "category_1                         0\n",
       "most_recent_sales_range            0\n",
       "most_recent_purchases_range        0\n",
       "avg_sales_lag3                    13\n",
       "avg_purchases_lag3                 0\n",
       "active_months_lag3                 0\n",
       "avg_sales_lag6                    13\n",
       "avg_purchases_lag6                 0\n",
       "active_months_lag6                 0\n",
       "avg_sales_lag12                   13\n",
       "avg_purchases_lag12                0\n",
       "active_months_lag12                0\n",
       "category_4                         0\n",
       "city_id                            0\n",
       "state_id                           0\n",
       "category_2                     11887\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (df_merchant.shape[0], df_merchant['merchant_id'].nunique())\n",
    "nans(df_merchant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, there exists some merchant whose id appears multiple times in this dataset. In catagory_2 lacks a significant amount of datas. We will check the unique value from category 4 to see if it is possible to repace nans to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change the object columns to numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "merchants_category_cols = ['merchant_id', 'merchant_group_id', 'merchant_category_id',\n",
    "                 'subsector_id', 'category_1', 'most_recent_sales_range', 'most_recent_purchases_range', 'city_id', 'state_id', 'category_4', 'category_2']\n",
    "\n",
    "merchants_numeric_cols = ['numerical_1', 'numerical_2', 'avg_sales_lag3', 'avg_purchases_lag3', 'active_months_lag3', 'avg_sales_lag6', 'avg_purchases_lag6', 'active_months_lag6',\n",
    "                'avg_sales_lag12', 'avg_purchases_lag12', 'active_months_lag12']\n",
    "\n",
    "assert len(merchants_numeric_cols) + len(merchants_category_cols) == len(df_merchant.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check category columns unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            merchant_id  merchant_group_id  merchant_category_id  \\\n",
      "3       M_ID_a70e9c5f81               5026                   792   \n",
      "4       M_ID_64456c37ce               2228                   222   \n",
      "7       M_ID_d8ff08219e              16430                   529   \n",
      "9       M_ID_d2162ed113             112122                    81   \n",
      "11      M_ID_73487fed26              17123                   427   \n",
      "...                 ...                ...                   ...   \n",
      "334686  M_ID_3111c6df35             107283                   690   \n",
      "334688  M_ID_59764e8cb1              17285                   309   \n",
      "334690  M_ID_a9d91682ad                 35                   241   \n",
      "334692  M_ID_725a60d404                 35                   544   \n",
      "334694  M_ID_9139332ccc                 35                   511   \n",
      "\n",
      "        subsector_id  numerical_1  numerical_2  category_1  \\\n",
      "3                  9    -0.057471    -0.057471           1   \n",
      "4                 21    -0.057471    -0.057471           1   \n",
      "7                 20    -0.057471    -0.057471           1   \n",
      "9                 29    -0.057471    -0.057471           1   \n",
      "11                27    -0.057471    -0.057471           1   \n",
      "...              ...          ...          ...         ...   \n",
      "334686             1    -0.057471    -0.057471           1   \n",
      "334688            21     0.329211    -0.057471           1   \n",
      "334690            17    -0.057471    -0.057471           1   \n",
      "334692            29    -0.057471    -0.057471           1   \n",
      "334694             7    -0.057471    -0.057471           1   \n",
      "\n",
      "        most_recent_sales_range  most_recent_purchases_range  avg_sales_lag3  \\\n",
      "3                             4                            4             NaN   \n",
      "4                             4                            4             NaN   \n",
      "7                             4                            4             NaN   \n",
      "9                             4                            4             NaN   \n",
      "11                            4                            4             NaN   \n",
      "...                         ...                          ...             ...   \n",
      "334686                        0                            0            0.95   \n",
      "334688                        0                            0            0.97   \n",
      "334690                        0                            0            0.96   \n",
      "334692                        0                            0            0.89   \n",
      "334694                        0                            0            0.94   \n",
      "\n",
      "        ...  avg_sales_lag6  avg_purchases_lag6  active_months_lag6  \\\n",
      "3       ...             NaN            4.666667                   6   \n",
      "4       ...             NaN            0.361111                   6   \n",
      "7       ...             NaN            1.666667                   6   \n",
      "9       ...             NaN            1.000000                   2   \n",
      "11      ...             NaN                 inf                   6   \n",
      "...     ...             ...                 ...                 ...   \n",
      "334686  ...            0.90            0.967786                   6   \n",
      "334688  ...            1.00            1.107380                   6   \n",
      "334690  ...            0.85            0.919159                   6   \n",
      "334692  ...            0.78            0.813473                   6   \n",
      "334694  ...            0.82            0.783000                   6   \n",
      "\n",
      "        avg_sales_lag12  avg_purchases_lag12  active_months_lag12  category_4  \\\n",
      "3                   NaN             3.833333                   12           1   \n",
      "4                   NaN             0.347222                   12           1   \n",
      "7                   NaN             1.500000                   11           1   \n",
      "9                   NaN             1.000000                    2           1   \n",
      "11                  NaN                  inf                   12           1   \n",
      "...                 ...                  ...                  ...         ...   \n",
      "334686             0.79             0.891154                   12           1   \n",
      "334688             1.05             1.120891                   12           1   \n",
      "334690             0.90             0.982781                   12           1   \n",
      "334692             0.59             0.606765                   12           1   \n",
      "334694             0.65             0.584000                   12           1   \n",
      "\n",
      "        city_id  state_id  category_2  \n",
      "3            -1        -1        -1.0  \n",
      "4            -1        -1        -1.0  \n",
      "7            -1        -1        -1.0  \n",
      "9            -1        -1        -1.0  \n",
      "11           -1        -1        -1.0  \n",
      "...         ...       ...         ...  \n",
      "334686       -1        -1        -1.0  \n",
      "334688       -1        -1        -1.0  \n",
      "334690       -1        -1        -1.0  \n",
      "334692       -1        -1        -1.0  \n",
      "334694       -1        -1        -1.0  \n",
      "\n",
      "[11887 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merchant[merchants_category_cols].nunique()\n",
    "df_merchant[merchants_category_cols].dtypes\n",
    "df_merchant['category_2'] .unique()\n",
    "df_merchant['category_2'].fillna(-1, inplace=True)\n",
    "cols = ['category_1', 'most_recent_sales_range', 'most_recent_purchases_range', 'category_4']\n",
    "df_merchant = reformat_dataframe(df_merchant, cols, change_object_col)\n",
    "print(df_merchant[df_merchant['category_2'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_group_id</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>numerical_1</th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>category_1</th>\n",
       "      <th>most_recent_sales_range</th>\n",
       "      <th>most_recent_purchases_range</th>\n",
       "      <th>avg_sales_lag3</th>\n",
       "      <th>avg_purchases_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sales_lag6</th>\n",
       "      <th>avg_purchases_lag6</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>category_4</th>\n",
       "      <th>city_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334683.000000</td>\n",
       "      <td>3.346960e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.346830e+05</td>\n",
       "      <td>3.346960e+05</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>3.346830e+05</td>\n",
       "      <td>3.346960e+05</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31028.736143</td>\n",
       "      <td>423.131663</td>\n",
       "      <td>25.116404</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>3.388233</td>\n",
       "      <td>3.382565</td>\n",
       "      <td>13.832993</td>\n",
       "      <td>inf</td>\n",
       "      <td>...</td>\n",
       "      <td>2.165079e+01</td>\n",
       "      <td>inf</td>\n",
       "      <td>5.947397</td>\n",
       "      <td>2.522771e+01</td>\n",
       "      <td>inf</td>\n",
       "      <td>11.599335</td>\n",
       "      <td>0.287126</td>\n",
       "      <td>102.917926</td>\n",
       "      <td>11.860942</td>\n",
       "      <td>2.259958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31623.043426</td>\n",
       "      <td>252.898046</td>\n",
       "      <td>9.807371</td>\n",
       "      <td>1.098154</td>\n",
       "      <td>1.070497</td>\n",
       "      <td>0.143488</td>\n",
       "      <td>0.753297</td>\n",
       "      <td>0.752935</td>\n",
       "      <td>2395.489999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.947108e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394936</td>\n",
       "      <td>5.251842e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.520138</td>\n",
       "      <td>0.452422</td>\n",
       "      <td>107.090673</td>\n",
       "      <td>6.176889</td>\n",
       "      <td>1.657263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-82.130000</td>\n",
       "      <td>3.334953e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.213000e+01</td>\n",
       "      <td>1.670447e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.213000e+01</td>\n",
       "      <td>9.832954e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3612.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>9.236499e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.500000e-01</td>\n",
       "      <td>9.022475e-01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.500000e-01</td>\n",
       "      <td>8.983333e-01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19900.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.016667e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010000e+00</td>\n",
       "      <td>1.026961e+00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.020000e+00</td>\n",
       "      <td>1.043361e+00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51707.250000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>1.146522e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.230000e+00</td>\n",
       "      <td>1.215575e+00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.290000e+00</td>\n",
       "      <td>1.266480e+00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>112586.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>183.735111</td>\n",
       "      <td>182.079322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>851844.640000</td>\n",
       "      <td>inf</td>\n",
       "      <td>...</td>\n",
       "      <td>1.513959e+06</td>\n",
       "      <td>inf</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.567408e+06</td>\n",
       "      <td>inf</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merchant_group_id  merchant_category_id   subsector_id    numerical_1  \\\n",
       "count      334696.000000         334696.000000  334696.000000  334696.000000   \n",
       "mean        31028.736143            423.131663      25.116404       0.011476   \n",
       "std         31623.043426            252.898046       9.807371       1.098154   \n",
       "min             1.000000             -1.000000      -1.000000      -0.057471   \n",
       "25%          3612.000000            222.000000      19.000000      -0.057471   \n",
       "50%         19900.000000            373.000000      27.000000      -0.057471   \n",
       "75%         51707.250000            683.000000      33.000000      -0.047556   \n",
       "max        112586.000000            891.000000      41.000000     183.735111   \n",
       "\n",
       "         numerical_2     category_1  most_recent_sales_range  \\\n",
       "count  334696.000000  334696.000000            334696.000000   \n",
       "mean        0.008103       0.021031                 3.388233   \n",
       "std         1.070497       0.143488                 0.753297   \n",
       "min        -0.057471       0.000000                 0.000000   \n",
       "25%        -0.057471       0.000000                 3.000000   \n",
       "50%        -0.057471       0.000000                 4.000000   \n",
       "75%        -0.047556       0.000000                 4.000000   \n",
       "max       182.079322       1.000000                 4.000000   \n",
       "\n",
       "       most_recent_purchases_range  avg_sales_lag3  avg_purchases_lag3  ...  \\\n",
       "count                334696.000000   334683.000000        3.346960e+05  ...   \n",
       "mean                      3.382565       13.832993                 inf  ...   \n",
       "std                       0.752935     2395.489999                 NaN  ...   \n",
       "min                       0.000000      -82.130000        3.334953e-01  ...   \n",
       "25%                       3.000000        0.880000        9.236499e-01  ...   \n",
       "50%                       4.000000        1.000000        1.016667e+00  ...   \n",
       "75%                       4.000000        1.160000        1.146522e+00  ...   \n",
       "max                       4.000000   851844.640000                 inf  ...   \n",
       "\n",
       "       avg_sales_lag6  avg_purchases_lag6  active_months_lag6  \\\n",
       "count    3.346830e+05        3.346960e+05       334696.000000   \n",
       "mean     2.165079e+01                 inf            5.947397   \n",
       "std      3.947108e+03                 NaN            0.394936   \n",
       "min     -8.213000e+01        1.670447e-01            1.000000   \n",
       "25%      8.500000e-01        9.022475e-01            6.000000   \n",
       "50%      1.010000e+00        1.026961e+00            6.000000   \n",
       "75%      1.230000e+00        1.215575e+00            6.000000   \n",
       "max      1.513959e+06                 inf            6.000000   \n",
       "\n",
       "       avg_sales_lag12  avg_purchases_lag12  active_months_lag12  \\\n",
       "count     3.346830e+05         3.346960e+05        334696.000000   \n",
       "mean      2.522771e+01                  inf            11.599335   \n",
       "std       5.251842e+03                  NaN             1.520138   \n",
       "min      -8.213000e+01         9.832954e-02             1.000000   \n",
       "25%       8.500000e-01         8.983333e-01            12.000000   \n",
       "50%       1.020000e+00         1.043361e+00            12.000000   \n",
       "75%       1.290000e+00         1.266480e+00            12.000000   \n",
       "max       2.567408e+06                  inf            12.000000   \n",
       "\n",
       "          category_4        city_id       state_id     category_2  \n",
       "count  334696.000000  334696.000000  334696.000000  334696.000000  \n",
       "mean        0.287126     102.917926      11.860942       2.259958  \n",
       "std         0.452422     107.090673       6.176889       1.657263  \n",
       "min         0.000000      -1.000000      -1.000000      -1.000000  \n",
       "25%         0.000000      -1.000000       9.000000       1.000000  \n",
       "50%         0.000000      69.000000       9.000000       1.000000  \n",
       "75%         1.000000     182.000000      16.000000       4.000000  \n",
       "max         1.000000     347.000000      24.000000       5.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merchant[merchants_numeric_cols].dtypes\n",
    "nans(df_merchant)\n",
    "df_merchant.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_group_id</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>numerical_1</th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>category_1</th>\n",
       "      <th>most_recent_sales_range</th>\n",
       "      <th>most_recent_purchases_range</th>\n",
       "      <th>avg_sales_lag3</th>\n",
       "      <th>avg_purchases_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sales_lag6</th>\n",
       "      <th>avg_purchases_lag6</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>category_4</th>\n",
       "      <th>city_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334683.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.346830e+05</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>3.346830e+05</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "      <td>334696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31028.736143</td>\n",
       "      <td>423.131663</td>\n",
       "      <td>25.116404</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>3.388233</td>\n",
       "      <td>3.382565</td>\n",
       "      <td>13.832993</td>\n",
       "      <td>2.145143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.165079e+01</td>\n",
       "      <td>2.390194</td>\n",
       "      <td>5.947397</td>\n",
       "      <td>2.522771e+01</td>\n",
       "      <td>2.529277</td>\n",
       "      <td>11.599335</td>\n",
       "      <td>0.287126</td>\n",
       "      <td>102.917926</td>\n",
       "      <td>11.860942</td>\n",
       "      <td>2.259958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31623.043426</td>\n",
       "      <td>252.898046</td>\n",
       "      <td>9.807371</td>\n",
       "      <td>1.098154</td>\n",
       "      <td>1.070497</td>\n",
       "      <td>0.143488</td>\n",
       "      <td>0.753297</td>\n",
       "      <td>0.752935</td>\n",
       "      <td>2395.489999</td>\n",
       "      <td>213.955844</td>\n",
       "      <td>...</td>\n",
       "      <td>3.947108e+03</td>\n",
       "      <td>194.324264</td>\n",
       "      <td>0.394936</td>\n",
       "      <td>5.251842e+03</td>\n",
       "      <td>174.419034</td>\n",
       "      <td>1.520138</td>\n",
       "      <td>0.452422</td>\n",
       "      <td>107.090673</td>\n",
       "      <td>6.176889</td>\n",
       "      <td>1.657263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-82.130000</td>\n",
       "      <td>0.333495</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.213000e+01</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.213000e+01</td>\n",
       "      <td>0.098330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3612.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.923650</td>\n",
       "      <td>...</td>\n",
       "      <td>8.500000e-01</td>\n",
       "      <td>0.902247</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.500000e-01</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19900.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010000e+00</td>\n",
       "      <td>1.026961</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.020000e+00</td>\n",
       "      <td>1.043361</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51707.250000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>1.146522</td>\n",
       "      <td>...</td>\n",
       "      <td>1.230000e+00</td>\n",
       "      <td>1.215575</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.290000e+00</td>\n",
       "      <td>1.266480</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>112586.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>183.735111</td>\n",
       "      <td>182.079322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>851844.640000</td>\n",
       "      <td>61851.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.513959e+06</td>\n",
       "      <td>56077.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.567408e+06</td>\n",
       "      <td>50215.555556</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merchant_group_id  merchant_category_id   subsector_id    numerical_1  \\\n",
       "count      334696.000000         334696.000000  334696.000000  334696.000000   \n",
       "mean        31028.736143            423.131663      25.116404       0.011476   \n",
       "std         31623.043426            252.898046       9.807371       1.098154   \n",
       "min             1.000000             -1.000000      -1.000000      -0.057471   \n",
       "25%          3612.000000            222.000000      19.000000      -0.057471   \n",
       "50%         19900.000000            373.000000      27.000000      -0.057471   \n",
       "75%         51707.250000            683.000000      33.000000      -0.047556   \n",
       "max        112586.000000            891.000000      41.000000     183.735111   \n",
       "\n",
       "         numerical_2     category_1  most_recent_sales_range  \\\n",
       "count  334696.000000  334696.000000            334696.000000   \n",
       "mean        0.008103       0.021031                 3.388233   \n",
       "std         1.070497       0.143488                 0.753297   \n",
       "min        -0.057471       0.000000                 0.000000   \n",
       "25%        -0.057471       0.000000                 3.000000   \n",
       "50%        -0.057471       0.000000                 4.000000   \n",
       "75%        -0.047556       0.000000                 4.000000   \n",
       "max       182.079322       1.000000                 4.000000   \n",
       "\n",
       "       most_recent_purchases_range  avg_sales_lag3  avg_purchases_lag3  ...  \\\n",
       "count                334696.000000   334683.000000       334696.000000  ...   \n",
       "mean                      3.382565       13.832993            2.145143  ...   \n",
       "std                       0.752935     2395.489999          213.955844  ...   \n",
       "min                       0.000000      -82.130000            0.333495  ...   \n",
       "25%                       3.000000        0.880000            0.923650  ...   \n",
       "50%                       4.000000        1.000000            1.016667  ...   \n",
       "75%                       4.000000        1.160000            1.146522  ...   \n",
       "max                       4.000000   851844.640000        61851.333333  ...   \n",
       "\n",
       "       avg_sales_lag6  avg_purchases_lag6  active_months_lag6  \\\n",
       "count    3.346830e+05       334696.000000       334696.000000   \n",
       "mean     2.165079e+01            2.390194            5.947397   \n",
       "std      3.947108e+03          194.324264            0.394936   \n",
       "min     -8.213000e+01            0.167045            1.000000   \n",
       "25%      8.500000e-01            0.902247            6.000000   \n",
       "50%      1.010000e+00            1.026961            6.000000   \n",
       "75%      1.230000e+00            1.215575            6.000000   \n",
       "max      1.513959e+06        56077.500000            6.000000   \n",
       "\n",
       "       avg_sales_lag12  avg_purchases_lag12  active_months_lag12  \\\n",
       "count     3.346830e+05        334696.000000        334696.000000   \n",
       "mean      2.522771e+01             2.529277            11.599335   \n",
       "std       5.251842e+03           174.419034             1.520138   \n",
       "min      -8.213000e+01             0.098330             1.000000   \n",
       "25%       8.500000e-01             0.898333            12.000000   \n",
       "50%       1.020000e+00             1.043361            12.000000   \n",
       "75%       1.290000e+00             1.266480            12.000000   \n",
       "max       2.567408e+06         50215.555556            12.000000   \n",
       "\n",
       "          category_4        city_id       state_id     category_2  \n",
       "count  334696.000000  334696.000000  334696.000000  334696.000000  \n",
       "mean        0.287126     102.917926      11.860942       2.259958  \n",
       "std         0.452422     107.090673       6.176889       1.657263  \n",
       "min         0.000000      -1.000000      -1.000000      -1.000000  \n",
       "25%         0.000000      -1.000000       9.000000       1.000000  \n",
       "50%         0.000000      69.000000       9.000000       1.000000  \n",
       "75%         1.000000     182.000000      16.000000       4.000000  \n",
       "max         1.000000     347.000000      24.000000       5.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_cols = ['avg_purchases_lag3', 'avg_purchases_lag6', 'avg_purchases_lag12']\n",
    "\n",
    "# replace infinity with second largest values\n",
    "df_merchant = reformat_dataframe(df_merchant, inf_cols, lambda df: df.replace(np.inf, df[df != np.inf].max()))\n",
    "df_merchant.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill nans with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merchant = reformat_dataframe(df_merchant, merchants_numeric_cols, lambda df: df.fillna(df.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Transaction and New Merchant Transaction Data Purge\n",
    "\n",
    "These two datasets will be purged all together bacause they are highly relevant. In order to process the datasets efficiently we will use a StreamerBuilder to process the data chunk by chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1963031 entries, 0 to 1963030\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   authorized_flag       object \n",
      " 1   card_id               object \n",
      " 2   city_id               int64  \n",
      " 3   category_1            object \n",
      " 4   installments          int64  \n",
      " 5   category_3            object \n",
      " 6   merchant_category_id  int64  \n",
      " 7   merchant_id           object \n",
      " 8   month_lag             int64  \n",
      " 9   purchase_amount       float64\n",
      " 10  purchase_date         object \n",
      " 11  category_2            float64\n",
      " 12  state_id              int64  \n",
      " 13  subsector_id          int64  \n",
      "dtypes: float64(2), int64(6), object(6)\n",
      "memory usage: 209.7+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chunksize=10 ** 6\n",
    "\n",
    "def histories_builder() -> StreamerBuilder[pd.DataFrame] :\n",
    "    return StreamerBuilder.build(pd.read_csv(os.path.join(DATA_DIR, \"historical_transactions.csv\"),\n",
    "                       chunksize=chunksize))\n",
    "\n",
    "def append_df(df1, df2):\n",
    "    return df1.append(df2)\n",
    "\n",
    "def sum_df(df1, df2):\n",
    "    return df1.add(df2)\n",
    "\n",
    "df_new_merchants = pd.read_csv(os.path.join(DATA_DIR, \"new_merchant_transactions.csv\"))\n",
    "df_new_merchants.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will firstly check the dulplciate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cols = []\n",
    "transactions_features = df_new_merchants.columns\n",
    "\n",
    "for col in df_new_merchants.columns:\n",
    "    if col in df_merchant.columns:\n",
    "        duplicate_cols.append(col)\n",
    "\n",
    "duplicate_cols = ['merchant_id', 'city_id', 'category_1', 'merchant_category_id', 'category_2', 'state_id', 'subsector_id']\n",
    "df_merchant = df_merchant.drop(duplicate_cols[1:], axis=1)\n",
    "df_merchant = df_merchant.loc[df_merchant['merchant_id'].drop_duplicates().index]\n",
    "df_merchant.to_csv(os.path.join(OUT_DIR, 'merchants_pre.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291242, 7)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchants[duplicate_cols].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_merchants['merchant_id'].nunique()\n",
    "cols = ['most_recent_sales_range', 'most_recent_purchases_range', 'merchant_id']\n",
    "df_new_merchants = df_new_merchants.merge(df_merchant[cols], how='left', on='merchant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_numeric = ['month_lag', 'installments', 'purchase_amount']\n",
    "transactions_category = ['card_id', 'authorized_flag', 'category_3', 'category_1', 'merchant_category_id', 'subsector_id', 'merchant_id', 'city_id', \"state_id\", 'category_2', 'most_recent_sales_range', 'most_recent_purchases_range']\n",
    "# reserved for time series model\n",
    "transactions_time_cols = ['purchase_date']\n",
    "\n",
    "\n",
    "assert len(df_new_merchants.columns) == len(transactions_category) + len(transactions_numeric) + len(transactions_time_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_id                         object\n",
       "authorized_flag                 object\n",
       "category_3                      object\n",
       "category_1                      object\n",
       "merchant_category_id             int64\n",
       "subsector_id                     int64\n",
       "merchant_id                     object\n",
       "city_id                          int64\n",
       "state_id                         int64\n",
       "category_2                     float64\n",
       "most_recent_sales_range        float64\n",
       "most_recent_purchases_range    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_merchants[transactions_category].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag                     0\n",
       "card_id                             0\n",
       "city_id                             0\n",
       "category_1                          0\n",
       "installments                        0\n",
       "category_3                      55922\n",
       "merchant_category_id                0\n",
       "merchant_id                     26216\n",
       "month_lag                           0\n",
       "purchase_amount                     0\n",
       "purchase_date                       0\n",
       "category_2                     111745\n",
       "state_id                            0\n",
       "subsector_id                        0\n",
       "most_recent_sales_range         26216\n",
       "most_recent_purchases_range     26216\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans(df_new_merchants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['authorized_flag', 'category_1', 'category_3']\n",
    "df_new_merchants = reformat_dataframe(df_new_merchants, features, change_object_col)\n",
    "\n",
    "\n",
    "# convert dtype to small int\n",
    "df_new_merchants['category_2'].fillna(-1, inplace=True)\n",
    "df_new_merchants['category_2'] = df_new_merchants['category_2'].astype(np.int8)\n",
    "df_new_merchants['category_1'] = df_new_merchants['category_1'].astype(np.int8)\n",
    "df_new_merchants['authorized_flag'] = df_new_merchants['authorized_flag'].astype(np.int8)\n",
    "df_new_merchants['installments'] = df_new_merchants['installments'].astype(np.int8)\n",
    "df_new_merchants['state_id'] = df_new_merchants['state_id'].astype(np.int8)\n",
    "df_new_merchants['city_id'] = df_new_merchants['city_id'].astype(np.int8)\n",
    "df_new_merchants['subsector_id'] = df_new_merchants['subsector_id'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1963031 entries, 0 to 1963030\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   authorized_flag              int8   \n",
      " 1   card_id                      object \n",
      " 2   city_id                      int8   \n",
      " 3   category_1                   int8   \n",
      " 4   installments                 int8   \n",
      " 5   category_3                   int64  \n",
      " 6   merchant_category_id         int64  \n",
      " 7   merchant_id                  object \n",
      " 8   month_lag                    int64  \n",
      " 9   purchase_amount              float64\n",
      " 10  purchase_date                object \n",
      " 11  category_2                   int8   \n",
      " 12  state_id                     int8   \n",
      " 13  subsector_id                 int8   \n",
      " 14  most_recent_sales_range      float64\n",
      " 15  most_recent_purchases_range  float64\n",
      "dtypes: float64(3), int64(3), int8(7), object(3)\n",
      "memory usage: 162.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# convert purchase date to timeseries\n",
    "datetime_index = pd.DatetimeIndex(df_new_merchants['purchase_date'])\n",
    "df_new_merchants.info()\n",
    "transactions_dtype = df_new_merchants.dtypes\n",
    "df_new_merchants['purchase_day'] = datetime_index.day\n",
    "df_new_merchants['purchase_month'] = datetime_index.month\n",
    "df_new_merchants['purchase_year'] = datetime_index.year\n",
    "df_new_merchants['purchase_hour_section'] = datetime_index.time\n",
    "\n",
    "\n",
    "transactions_path = os.path.join(OUT_DIR, 'transactions_pre.csv')\n",
    "if os.path.exists(transactions_path):\n",
    "    os.remove(transactions_path)\n",
    "df_new_merchants.to_csv(transactions_path,mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to fill numerical columns since they don't have nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13912"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reserved for large memory write-ins\n",
    "del df_new_merchants, datetime_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histories_nans = histories_builder().map(nans).reduce(sum_df).collect(identity)\n",
    "# print(histories_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can discover the history columns and new merchants columns are the same, so we can easily using the above methods again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_index(df: pd.DataFrame):\n",
    "    _datetime_index = pd.DatetimeIndex(df['purchase_date'])\n",
    "    df['purchase_day'] = _datetime_index.day\n",
    "    df['purchase_month'] = _datetime_index.month\n",
    "    df['purchase_year'] = _datetime_index.year\n",
    "    df['purchase_hour_section'] = _datetime_index.date\n",
    "    return df\n",
    "\n",
    "def convert_columns(df: pd.DataFrame):\n",
    "    df['category_2'].fillna(-1, inplace=True)\n",
    "    return df\n",
    "\n",
    "to_csv_builder = histories_builder() \\\n",
    "                    .map(lambda df: reformat_dataframe(df, features, change_object_col)) \\\n",
    "                    .map(lambda df: df.merge(df_merchant[cols], how='left', on='merchant_id')) \\\n",
    "                    .map(convert_columns) \\\n",
    "                    .map(add_datetime_index)\n",
    "\n",
    "# write to csv\n",
    "to_csv_builder.consume(lambda df: df.to_csv(transactions_path, mode='a', index=False))\n",
    "\n",
    "del to_csv_builder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_DIR = os.path.join(DATA_DIR, \"pre\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will extract each columns by their numerical features and append them to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggs_cols(features) -> t.Tuple[t.Dict[str, str], t.List[str]]:\n",
    "    aggs = {}\n",
    "    for col in transactions_numeric and features:\n",
    "        aggs[col] = ['nunique', 'mean', 'min', 'max', 'var', 'skew', 'sum']\n",
    "    for col in transactions_category and features:\n",
    "        aggs[col] = ['nunique']\n",
    "    aggs['card_id'] = ['size', 'count']\n",
    "    cols = []\n",
    "    for key in aggs.keys():\n",
    "        cols.extend([key+\"_\"+stat for stat in aggs[key]])\n",
    "    return aggs, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @enable_logging(\"append_new_columns.txt\")\n",
    "def append_new_columns(transaction, aggs, cols):\n",
    "    df = transaction[transaction['month_lag'] < 0].groupby('card_id').agg(aggs)\n",
    "    df.columns = [co+ \"_hist\" for co in cols]\n",
    "    df2 = transaction[transaction['month_lag'] >= 0].groupby('card_id').agg(aggs)\n",
    "    df2.columns =[co + \"_hist\" for co in cols]\n",
    "    df = df.merge(df2, how='left')\n",
    "    df2 = transaction.groupby('card_id').agg(aggs)\n",
    "    df2.columns = cols\n",
    "    if not df.empty:\n",
    "        df = df.merge(df2, how='left')\n",
    "    else:\n",
    "        df = df2.copy()\n",
    "    del transaction\n",
    "    gc.collect()\n",
    "    df = df.reset_index()\n",
    "    # logging.debug(str(df))\n",
    "    return df\n",
    "\n",
    "\n",
    "@enable_logging(\"write_to_csv.txt\")\n",
    "def write_to_csv(df):\n",
    "    train = pd.read_csv(os.path.join(PRE_DIR, \"train_pre.csv\"))\n",
    "    train = train.merge(df, how='left', on='card_id')\n",
    "    logging.debug(f'Training df after first merge')\n",
    "\n",
    "    test = pd.read_csv(os.path.join(PRE_DIR, \"test_pre.csv\"))\n",
    "    test = test.merge(df, how='left', on='card_id')\n",
    "\n",
    "    train.to_csv(os.path.join(PRE_DIR, \"train_groupby.csv\"), mode='a')\n",
    "    test.to_csv(os.path.join(PRE_DIR, \"test_groupby.csv\"), mode='a')\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334633 entries, 0 to 334632\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   merchant_id                  334633 non-null  object \n",
      " 1   merchant_group_id            334633 non-null  int64  \n",
      " 2   numerical_1                  334633 non-null  float64\n",
      " 3   numerical_2                  334633 non-null  float64\n",
      " 4   most_recent_sales_range      334633 non-null  int64  \n",
      " 5   most_recent_purchases_range  334633 non-null  int64  \n",
      " 6   avg_sales_lag3               334633 non-null  float64\n",
      " 7   avg_purchases_lag3           334633 non-null  float64\n",
      " 8   active_months_lag3           334633 non-null  int64  \n",
      " 9   avg_sales_lag6               334633 non-null  float64\n",
      " 10  avg_purchases_lag6           334633 non-null  float64\n",
      " 11  active_months_lag6           334633 non-null  int64  \n",
      " 12  avg_sales_lag12              334633 non-null  float64\n",
      " 13  avg_purchases_lag12          334633 non-null  float64\n",
      " 14  active_months_lag12          334633 non-null  int64  \n",
      " 15  category_4                   334633 non-null  int64  \n",
      "dtypes: float64(8), int64(7), object(1)\n",
      "memory usage: 40.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_groupby, test_groupby = os.path.join(PRE_DIR, \"train_groupby.csv\"), os.path.join(PRE_DIR, \"test_groupby.csv\")\n",
    "if os.path.exists(train_groupby):\n",
    "    os.remove(train_groupby)\n",
    "if os.path.exists(test_groupby):\n",
    "    os.remove(test_groupby)\n",
    "\n",
    "aggs, cols = create_aggs_cols(transactions_features)\n",
    "\n",
    "dtypes = transactions_dtype.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now we can read_csv directly because we specifies the dtype\n",
    "# transactions = pd.read_csv(os.path.join(PRE_DIR, \"new_merchant_pre.csv\"),\n",
    "#                            dtype=dtypes)\n",
    "# merchants = pd.read_csv(os.path.join(PRE_DIR, \"merchants_pre.csv\"))\n",
    "# # print(transactions.info())\n",
    "# print(merchants.info())\n",
    "\n",
    "# transactions = append_new_columns(transactions, aggs, cols)\n",
    "# write_to_csv(transactions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccbb4ca7fe902b23c4d3bf398cc69bd54ad114cdf2cf797081a3177c4f0863aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('lama_gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
