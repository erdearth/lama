{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Baseline Model </h3>\n",
    "\n",
    "We first make a random forset model as a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from data import DATA_DIR\n",
    "from lama.preprocessing.DataProcessor import nans, reformat_dataframe\n",
    "\n",
    "logger = logging.getLogger()\n",
    "PRE_DIR = os.path.join(DATA_DIR, \"pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need card id anynore since we don't have to merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/kcj0_5zx05b_z6jvrr00b12w0000gn/T/ipykernel_45656/2400326108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(PRE_DIR, \"train_groupby.csv\"))\n",
    "test = pd.read_csv(os.path.join(PRE_DIR, \"test_groupby.csv\"))\n",
    "\n",
    "features = train.columns.tolist()\n",
    "features.remove('target')\n",
    "features.remove('card_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETER_SPACE = {\n",
    "    \"n_estimators\": range(100),\n",
    "    \"min_samples_leaf\": range(50),\n",
    "    \"min_samples_split\": range(10),\n",
    "    \"max_depth\": range(20),\n",
    "    \"max_features\": [\"auto\", 80]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8202826   0.39291325  0.68805599 ...  0.09349415 -4.67658938\n",
      " -1.85941301]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "224 fits failed out of a total of 800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 384, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/ensemble/_base.py\", line 138, in _validate_estimator\n",
      "    raise ValueError(\n",
      "ValueError: n_estimators must be greater than zero, got 0.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "144 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 211, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 235, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 0\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 442, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/concurrent/futures/_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/concurrent/futures/_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "ValueError: min_samples_leaf must be at least 1 or in (0, 0.5], got 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -2.85622664 -2.73307669 -2.69204259\n",
      " -2.67453557 -2.66107082 -2.6525208  -2.64581012 -2.6404633  -2.6362021\n",
      "         nan -2.85423569 -2.73036133 -2.68988519 -2.67368061 -2.65988375\n",
      " -2.65117042 -2.64474794 -2.63985493 -2.63613462         nan -2.83822483\n",
      " -2.72257824 -2.68566813 -2.66973505 -2.65599374 -2.6473319  -2.64059719\n",
      " -2.63549758 -2.63237149         nan -2.83822483 -2.72257824 -2.68566813\n",
      " -2.66973505 -2.65599374 -2.6473319  -2.64059719 -2.63549758 -2.63237149\n",
      "         nan -2.84631574 -2.72206797 -2.68316807 -2.66656978 -2.65180579\n",
      " -2.64324433 -2.63688596 -2.63273375 -2.63005496         nan -2.84631574\n",
      " -2.72206797 -2.68316807 -2.66656978 -2.65180579 -2.64324433 -2.63688596\n",
      " -2.63273375 -2.63005496         nan -2.83575831 -2.7187293  -2.6807288\n",
      " -2.66492874 -2.65129038 -2.64271656 -2.63629197 -2.63192244 -2.62890718\n",
      "         nan -2.83575831 -2.7187293  -2.6807288  -2.66492874 -2.65129038\n",
      " -2.64271656 -2.63629197 -2.63192244 -2.62890718         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan -2.85842046 -2.72906487 -2.68742485 -2.66728341 -2.65175921\n",
      " -2.64289755 -2.63702132 -2.63283107 -2.62909218         nan -2.83001106\n",
      " -2.72096525 -2.68616701 -2.66794906 -2.6530491  -2.64595631 -2.63975155\n",
      " -2.63557231 -2.63473908         nan -2.83309841 -2.72207977 -2.68219579\n",
      " -2.66300012 -2.65030624 -2.64225918 -2.63721423 -2.63266109 -2.63017501\n",
      "         nan -2.83309841 -2.72207977 -2.68219579 -2.66300012 -2.65030624\n",
      " -2.64225918 -2.63721423 -2.63266109 -2.63017501         nan -2.83507075\n",
      " -2.72377018 -2.68226361 -2.66295975 -2.65090208 -2.64252417 -2.63749192\n",
      " -2.63272121 -2.63080516         nan -2.83507075 -2.72377018 -2.68226361\n",
      " -2.66295975 -2.65090208 -2.64252417 -2.63749192 -2.63272121 -2.63080516\n",
      "         nan -2.8217686  -2.71151205 -2.67926909 -2.6614012  -2.64878232\n",
      " -2.63963163 -2.63334553 -2.62925136 -2.62583427         nan -2.8217686\n",
      " -2.71151205 -2.67926909 -2.6614012  -2.64878232 -2.63963163 -2.63334553\n",
      " -2.62925136 -2.62583427         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan -2.96229373\n",
      " -2.77726684 -2.71650131 -2.69266454 -2.67279055 -2.65964765 -2.6496954\n",
      " -2.64354639 -2.63841925         nan -2.9481476  -2.77112695 -2.71507067\n",
      " -2.69189542 -2.67285532 -2.65913259 -2.64925533 -2.64293494 -2.63809858\n",
      "         nan -2.92488502 -2.76315027 -2.70926503 -2.68455897 -2.66546754\n",
      " -2.6530281  -2.64394507 -2.6377267  -2.63372359         nan -2.92488502\n",
      " -2.76315027 -2.70926503 -2.68455897 -2.66546754 -2.6530281  -2.64394507\n",
      " -2.6377267  -2.63372359         nan -2.93307274 -2.76139769 -2.7086641\n",
      " -2.68487909 -2.66437458 -2.65202917 -2.64233686 -2.63604851 -2.63206683\n",
      "         nan -2.93307274 -2.76139769 -2.7086641  -2.68487909 -2.66437458\n",
      " -2.65202917 -2.64233686 -2.63604851 -2.63206683         nan -2.91983453\n",
      " -2.75433086 -2.70387227 -2.68138331 -2.66114535 -2.64908154 -2.63992117\n",
      " -2.63438471 -2.63031259         nan -2.91983453 -2.75433086 -2.70387227\n",
      " -2.68138331 -2.66114535 -2.64908154 -2.63992117 -2.63438471 -2.63031259\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -2.91774311 -2.76553196 -2.70714898\n",
      " -2.68259355 -2.66451007 -2.65551503 -2.64667476 -2.6406142  -2.63669408\n",
      "         nan -2.92597932 -2.76895508 -2.70900592 -2.68255526 -2.6629477\n",
      " -2.65265078 -2.64435953 -2.63977398 -2.63597701         nan -2.92829286\n",
      " -2.76411813 -2.70811297 -2.67911854 -2.6628802  -2.65084249 -2.64349608\n",
      " -2.6380102  -2.63397201         nan -2.92829286 -2.76411813 -2.70811297\n",
      " -2.67911854 -2.6628802  -2.65084249 -2.64349608 -2.6380102  -2.63397201\n",
      "         nan -2.9269866  -2.75728741 -2.69707151 -2.67273088 -2.65381867\n",
      " -2.64193397 -2.63601264 -2.63026358 -2.62598027         nan -2.9269866\n",
      " -2.75728741 -2.69707151 -2.67273088 -2.65381867 -2.64193397 -2.63601264\n",
      " -2.63026358 -2.62598027         nan -2.91917386 -2.75598885 -2.70154679\n",
      " -2.67469921 -2.65644986 -2.64516286 -2.6369226  -2.63121619 -2.62736446\n",
      "         nan -2.91917386 -2.75598885 -2.70154679 -2.67469921 -2.65644986\n",
      " -2.64516286 -2.6369226  -2.63121619 -2.62736446]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestRegressor(n_jobs=15, random_state=42),\n",
       "             param_grid={'max_depth': [9, 10], 'max_features': ['auto', 80],\n",
       "                         'min_samples_leaf': range(0, 5),\n",
       "                         'min_samples_split': [2, 3],\n",
       "                         'n_estimators': range(0, 10)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(criterion='squared_error', n_jobs=16, random_state=42)\n",
    "grid = GridSearchCV(clf, PARAMETER_SPACE, cv=2, scoring='neg_mean_squared_error')\n",
    "print(train['target'].values)\n",
    "grid.fit(train[features].values, train['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'max_features': 80,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 9}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = np.sqrt(-grid.best_score_)\n",
    "_result = \\\n",
    "{\n",
    "    \"model\": \"RandomForestRegressor\",\n",
    "    \"best_params\": grid.best_params_,\n",
    "    \"best_score\": best_score,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lama_gpu/lib/python3.9/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test['target'] = grid.best_estimator_.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "RESULT_DIR = os.path.join(DATA_DIR, \"result\")\n",
    "test[['card_id', 'target']].to_csv(os.path.join(RESULT_DIR, \"submission_random_forest_1.csv\"), index=False)\n",
    "with open(os.path.join(RESULT_DIR, \"hyperparameters\"), \"a\") as file:\n",
    "    file.write(json.dumps(_result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submit our first baseline model into kagggle, we get the result.\n",
    "\n",
    "<img src=\"../../assets/img/Screenshot_1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this result is not very performing. So we will try out other model or make hyperparameter optimizations based on this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Baseline Model </h3>\n",
    "\n",
    "Now we try to build the model the second time, by implementing PCA and other filter model, we will run our random forest model a second time, hoping it achieve a better performance"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccbb4ca7fe902b23c4d3bf398cc69bd54ad114cdf2cf797081a3177c4f0863aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('lama_gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
